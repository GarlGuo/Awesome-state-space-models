For sequence modelling, the phenomenon of in-context learning is interesting in the sense that foundation models can be applied to help the downstream tasks. 

1. The mechanistic basis of data dependence and abrupt learning in an in-context classification task (https://openreview.net/forum?id=aN4Jf6Cx69)



2. ONE STEP OF GRADIENT DESCENT IS PROVABLY THE OPTIMAL IN-CONTEXT LEARNER WITH ONE LAYER OF LINEAR SELF-ATTENTION(https://openreview.net/forum?id=8p3fu56lKc&noteId=n3z3Y6l28Q)



3. In-Context Learning Dynamics with Random Binary Sequences (https://openreview.net/forum?id=62K7mALO2q)

    We propose a Cognitive Interpretability framework that enables us to analyze in-context learning dynamics to understand latent concepts in LLMs underlying behavioral patterns. This provides a more nuanced understanding than success-or-failure evaluation benchmarks, but does not require observing internal activations as a mechanistic interpretation of circuits would require.
    


4. How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression? (https://openreview.net/forum?id=vSh5ePa0ph)

    In this paper, we study ICL in one of its simplest setups: pretraining a single-layer linear attention model for lin- ear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. 



5. Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions

